{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af010fe9",
   "metadata": {},
   "source": [
    "Day 4: Feature Engineering\n",
    "--------------------------\n",
    "1. Models don't understand meaning, only numbers<br>\n",
    "We're tranforming the data to machine readable form\n",
    "\n",
    "Tasks:-<br>\n",
    "- âš™ï¸ Encode categorical variables\n",
    "- ðŸ“ Scale numerical features\n",
    "- ðŸ” Transform skewed data\n",
    "- ðŸ§ª Prepare data for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd7f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading necessary libraries and the dataframe\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/cleaned_train.csv\")\n",
    "\n",
    "\n",
    "# Task1 : separating features and target variable\n",
    "X = df.drop(\"SalePrice\", axis=1) # Axis=1 for columns\n",
    "y = df[\"SalePrice\"]\n",
    "# Separating is needed for the model to predict SalePrice(Y-Target Variable) based on other features(X-Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9137cdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded and Scaled Features Shape: (1460, 230)\n",
      "Log Transformed Target Shape: (1460,)\n"
     ]
    }
   ],
   "source": [
    "# Task 2: Encoding categorical variables\n",
    "X_encoded = pd.get_dummies(X, drop_first=True) # drop_first = True to avoid multicollinearity\n",
    "\n",
    "# Task 3: Scaling(standardizing) numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_encoded)\n",
    "# X_scaled is now a numpy array\n",
    "# Ready for regression\n",
    "\n",
    "# Task 4: Log transform Variable to help with skewness\n",
    "import numpy as np\n",
    "y_log = np.log1p(y)  # log1p to handle zero values if any\n",
    "\n",
    "# Final Sanity Check - Making sure x and y have same number of rows and no NaN values(i.e same shape)\n",
    "# Proffessionals do this check to ensure data integrity before model training\n",
    "print(\"Encoded and Scaled Features Shape:\", X_scaled.shape)\n",
    "print(\"Log Transformed Target Shape:\", y_log.shape)\n",
    "# same number of rows and no NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9a81d5",
   "metadata": {},
   "source": [
    "Review questions\n",
    "----------------\n",
    "1. Why regression doesn't do strings.(Why we encode data)\n",
    ">Regression models operate on numerical mathematics (multiplication, summation, optimization). Text has no inherent numeric meaning, so it must be encoded into numbers.\n",
    "\n",
    "2. Why Scaling is important and we do it.\n",
    ">Scaling matters because features with large numerical ranges can dominate model learning, even if they are not more important. Scaling ensures fair contribution from all features\n",
    "\n",
    "3. Why we separated Features and Target Variables into X and Y respectively.\n",
    ">We separate X (features) and y (target) because supervised learning trains a model to learn the relationship between inputs and outputs. Mixing them would cause data leakage and invalidate training and evaluation.<br>\n",
    ">i.e the model would be cheating - Core ML logic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
